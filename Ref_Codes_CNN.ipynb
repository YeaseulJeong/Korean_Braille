{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python] [CNN]점자번역 프로그램(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ready(): \n",
    "    images_dir = './images' \n",
    "    \n",
    "    datagen = ImageDataGenerator(rotation_range=5, \n",
    "                                 shear_range=5, \n",
    "                                 validation_split=0.2, \n",
    "                                ) #20%를 검증모델로 사용. \n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(images_dir, \n",
    "                                                  target_size=(36,36), \n",
    "                                                  subset='training')\n",
    "    \n",
    "    val_generator = datagen.flow_from_directory(images_dir, \n",
    "                                                target_size=(36,36), \n",
    "                                                subset='validation') \n",
    "    \n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path): \n",
    "    images_dir = img_path \n",
    "    datagen = ImageDataGenerator() \n",
    "    real_generator = datagen.flow_from_directory(images_dir, \n",
    "                                                 target_size=(36, 36)) \n",
    "    \n",
    "    return real_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python] [CNN]점자번역 프로그램(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import layers as L\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_model(train,val):\n",
    "    K.clear_session()\n",
    "\n",
    "    model_ckpt = ModelCheckpoint('BrailleNet.h5',save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(patience=8,verbose=1)\n",
    "    early_stop = EarlyStopping(patience=20,verbose=2)\n",
    "\n",
    "    entry = L.Input(shape=(36,36,3))\n",
    "    x = L.SeparableConv2D(64,(3,3),activation='relu',padding ='same')(entry)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(128,(3,3),activation='relu',padding ='same')(x)\n",
    "    x = L.MaxPooling2D((2,2))(x)\n",
    "\n",
    "    x = L.SeparableConv2D(256,(2,2),activation='relu',padding ='same')(x)\n",
    "    x = L.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    x = L.Dense(256)(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(64,kernel_regularizer=l2(2e-4))(x)\n",
    "    x = L.LeakyReLU()(x)\n",
    "    x = L.Dense(27,activation='softmax')(x)\n",
    "\n",
    "    model = Model(entry,x)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit_generator(train,validation_data=val,epochs=666,\n",
    "                                  callbacks=[model_ckpt,reduce_lr,early_stop],verbose=0)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acc_loss(history):\n",
    "    # 평가 결과 도식화\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, loss_ax = plt.subplots(figsize=(10, 5))\n",
    "    acc_ax = loss_ax.twinx()\n",
    "    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "    acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python] [CNN]점자번역 프로그램(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    from keras.models import load_model\n",
    "    model = load_model('BrailleNet.h5')\n",
    "    return model\n",
    "\n",
    "def acc_chk(model, val):\n",
    "    acc = model.evaluate_generator(val)[1]\n",
    "    print('model accuracy: {}'.format(round(acc,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class img_devide():\n",
    "    def __init__(self,img_path):\n",
    "        self.img_path = img_path\n",
    "        self.path = ''\n",
    "        self.call_num = 0\n",
    "        self.lengh = 0\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.img = ''\n",
    "\n",
    "\n",
    "    def create_dir(self):\n",
    "        try:\n",
    "            os.mkdir('./test/a')\n",
    "            print('create new dir')\n",
    "        except:\n",
    "            print('already exist')\n",
    "            pass\n",
    "        self.path = './test/a'\n",
    "\n",
    "    def devide_img(self):\n",
    "        self.img = Image.open(self.img_path)\n",
    "        area = (0+self.call_num*self.height,0,self.width/self.lengh*(self.call_num+1),self.height)\n",
    "        cropped_img = self.img.crop(area)\n",
    "        cropped_img.save(self.path + '/'+str(self.call_num)+'.jpg')\n",
    "\n",
    "        self.call_num+=1\n",
    "\n",
    "\n",
    "    def set_image(self):\n",
    "        self.img = Image.open(self.img_path)\n",
    "        self.width = self.img.size[0]\n",
    "        self.height = self.img.size[1]\n",
    "        self.lengh = int(self.width / self.height)\n",
    "\n",
    "    def remove_file(self):\n",
    "        try:\n",
    "            os.remove(self.path+'/'+str(self.call_num-1)+'.jpg')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def remove_dir(self) :\n",
    "        try:\n",
    "            os.rmdir(self.path)\n",
    "        except :\n",
    "            print('fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python] [CNN]점자번역 프로그램(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(num):\n",
    "\n",
    "    if num == 26:\n",
    "        return  ' '\n",
    "    else:\n",
    "        num_tr = num+97\n",
    "        return chr(num_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "class Predic():\n",
    "    result = []\n",
    "    def Predict(self,model,real):\n",
    "        my_list = model.predict(real)\n",
    "        index, value = max(enumerate(my_list[0]), key=operator.itemgetter(1))\n",
    "        print(index,alpha(index))\n",
    "        self.result.append(alpha(index))\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def reset(self):\n",
    "        self.result = []\n",
    "\n",
    "def chk_trans():\n",
    "    for i in range(0, 27):\n",
    "        print(str(i) + ':' + alpha(i),end='  ')\n",
    "        if i%3 ==2 :\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 오류 해결 (keras_scratch_graph)\n",
    "#import keraserr\n",
    "#keraserr.fixerr()\n",
    "\n",
    "## 이미지 준비 *한번 실행되면 다시 실행할 필요 없음.\n",
    "# import Rdy_image\n",
    "Rdy_image.Preset()\n",
    "\n",
    "## data Generator 테스트, 검증 데이터 생성\n",
    "# import DATAGenerator\n",
    "train_generator, val_generator = DATAGenerator.data_ready()\n",
    "\n",
    "#MAKE MODEL *한번 모델이 생성되면 다시 실행할 필요 없음\n",
    "# import Make_model\n",
    "#hist = Make_model.Make_model(train_generator,val_generator)\n",
    "#Make_model.print_acc_loss(hist)\n",
    "\n",
    "# BrailleNet에 저장된 모델을 불러옴.\n",
    "# acc확인\n",
    "# import Load_model\n",
    "model = Load_model.load_model()\n",
    "acc = Load_model.acc_chk(model,val_generator)\n",
    "\n",
    "# 사진 데이터 불러오기, 예측\n",
    "# import divide\n",
    "# import Predict\n",
    "\n",
    "#path = 'D:/ML/Project_f/real/a/l.jpg'\n",
    "\n",
    "def action(path):\n",
    "\n",
    "    Predict.chk_trans()\n",
    "    b = Predict.Predic()\n",
    "    a = divide.img_devide(path)\n",
    "\n",
    "    a.create_dir()\n",
    "    a.set_image()\n",
    "    b.reset()\n",
    "\n",
    "    for i in range(0,a.lengh):\n",
    "        a.devide_img()\n",
    "        real = DATAGenerator.load_image('./test')\n",
    "        b.Predict(model,real)\n",
    "        a.remove_file()\n",
    "\n",
    "\n",
    "    print(b.result)\n",
    "    result = ''.join(b.result)\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
